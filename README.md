# Dataset Processor

Some basic tools for importing and pre-processing datasets for training object detectors -currently intended to be used with ultralytics based object detectors/training. Boxes & keypoints are supported. For keypoints it has been tested with 17-point coco-pose and 5-point retinface keypoints (and both together). 

Basic functionality is an dataset builder pipeline with the following optional stages:

- **Import** images/labels from standard datasets: currently supported datsets (MS Coco, Openimages, Objects 365, Widerface, anything exported from Roboflow). Map classes of imported datasets to target classes (including N->1)
- **make_hard** Measures the 'difficults' of imported images against an object detector and import only a subset of hardest images
- **add_objects** Attempt to correct for missing labels in the dataset (unfortunately seems common). Uses an expensive object detector/high resolution to add in missing labels. Also this stage adds labels for classes that are not labelled in the dataset (e.g. adding face boxes to Coco)
- **add_pose** Uses a high quality pose detector to add pose points (typically 17 coco-style pose points), taking advantage of the fact that pose boxes must be consistent with existing person boxes
- **add_faces** Uses a high quality face detector to add missing face boxes and/or 5-point facial keypoints, taking advantage of the fact that added faces must be consistent with existing person boxes
- **normalise** Checks all the label data is in-bounds etc
- **add_backgrounds** From an imported dataset considers all the images that have **zero** classes of interest labelled (i.e. are 'backgrounds') and runs an object detector to find the 'hardest' i.e. those with the most false positives, and combine those into the created dataset
- **merge** Combines multiple created datasets together

Additional functionality to measure box and keypoint mAP is provided in map.py. 

## Installing/setup

- You ideally need a GPU with pytorch that supports ultralytics detectors
- Have already downloaded the datasets you are interested in
- The script by default assumes they are in /mldata/downloaded_datasets but this is easy to change - see the individual 'loaders' in the loaders folder
- Similarly output datasets are put in /mldata by default but you can change this by setting MLDATA_LOCATION environment variable

I run this with a 3090 GPU. Some of the pipeline stages take a while - for example to fully create a 100K image dataset from objects365 (>1M source images) with all pipeline stages takes around 5 hours on my 3090.

Set up your conda environment as normal:

**conda env create -f environment.yml**

**conda activate dataset-processor**

## Running

Generating a dataset:

**python build_dataset.py --config data/dataset_test.json**

Generating mAP results:

**python map.py --config data/map_ultralytics.json**

In each case the json condif files contains numerous changable parameters. Hopefully it's obvious as I am too lazy to document....

## License

Released under AGP3.0, see LICENSE. It's intended you not use this, or anything generated by it, for commercial use. If you are interested other use cases please reach out bernandocribbenza@gmail.com. 

Please also respect the licenses of any datasets you use!



